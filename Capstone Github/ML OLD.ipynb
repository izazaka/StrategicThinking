{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c828811",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/anastasiyaigonina/reviews-sentiment-topic-modeling-clustering\n",
    "\n",
    "The experiment performed joining negative and neutral can be found in this link:\n",
    "\n",
    "http://localhost:8889/notebooks/Documents/GitHub/StrategicThinking/Testing%20ML%20no%20neutral.ipynb\n",
    "\n",
    "Or in my GitHub Repository: https://github.com/izazaka/StrategicThinking\n",
    "\n",
    "ML from this\n",
    "\n",
    "https://www.kaggle.com/code/anastasiyaigonina/reviews-sentiment-topic-modeling-clustering#Sentiment-Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca82d14",
   "metadata": {},
   "source": [
    "## Sentiment Intensity Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(review):\n",
    "    scores = sia.polarity_scores(review)\n",
    "    sentiment_score = scores[\"compound\"]\n",
    "    if sentiment_score > 0.1:\n",
    "        return \"positive\"\n",
    "    elif sentiment_score < -0.1:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "    \n",
    "\n",
    "ml2 = ml.copy()\n",
    "ml2[\"Predicted_Sentiment\"] = ml2[\"cleaned_text\"].apply(get_sentiment)\n",
    "\n",
    "\n",
    "print(\"Number of positive reviews:\", len(ml2[ml2[\"Predicted_Sentiment\"] == \"positive\"]))\n",
    "print(\"Number of negative reviews:\", len(ml2[ml2[\"Predicted_Sentiment\"] == \"negative\"]))\n",
    "print(\"Number of neutral reviews:\", len(ml2[ml2[\"Predicted_Sentiment\"] == \"neutral\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d80749",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml2[\"True_Sentiment\"] = ml2[\"starRating\"].map({1: \"negative\", \n",
    "                                           2: \"negative\", \n",
    "                                           3: \"neutral\", \n",
    "                                           4: \"positive\", \n",
    "                                           5: \"positive\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731238ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(ml2[\"True_Sentiment\"], ml2[\"Predicted_Sentiment\"])\n",
    "\n",
    "labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "sns.heatmap(cm, annot = True, cmap = \"Reds\", fmt = \"g\", xticklabels = labels, yticklabels = labels)\n",
    "plt.xlabel(\"Predicted sentiment\")\n",
    "plt.ylabel(\"True sentiment\")\n",
    "plt.title(\"Confusion matrix for sentiment analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbda32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification report:\\n\", classification_report(ml2[\"True_Sentiment\"], \n",
    "                                                          ml2[\"Predicted_Sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6c2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecc89387",
   "metadata": {},
   "source": [
    "## Random Forest with Star Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b4e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = [4, 5]\n",
    "neutral = [3]\n",
    "negative = [1, 2]\n",
    "\n",
    "def map_sentiment(rating):\n",
    "    if rating in positive:\n",
    "        return 2\n",
    "    elif rating in negative:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "ml[\"sentiment\"]= ml[\"starRating\"].apply(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b64d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1, 3), max_features = 1000, tokenizer = word_tokenize)\n",
    "X = tfidf.fit_transform(ml[\"cleaned_text\"])\n",
    "y = ml[\"sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predicted_rf = rf.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, predicted_rf)\n",
    "print('Accuracy:', accuracy_rf)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Accuracy on Training Set:\", accuracy_train)\n",
    "print(\"Accuracy on Test Set:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3eb3e",
   "metadata": {},
   "source": [
    "### Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59723d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(tokenizer = word_tokenize)),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'tfidf__max_features': [500, 1000, 2000],\n",
    "    'clf__n_estimators': [50, 100, 200],\n",
    "    'clf__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv = 5, n_jobs=- 1, verbose = 1)\n",
    "\n",
    "grid_search.fit(ml[\"cleaned_text\"], ml[\"sentiment\"])\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31dcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e43ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1, 1), max_features = 500, \n",
    "                        tokenizer = word_tokenize)\n",
    "X = tfidf.fit_transform(ml[\"cleaned_text\"])\n",
    "y = ml[\"sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predicted_rf = rf.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, predicted_rf)\n",
    "print('Accuracy:', accuracy_rf)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1813cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Accuracy on Training Set:\", accuracy_train)\n",
    "print(\"Accuracy on Test Set:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12637668",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 12)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv = kfold, scoring = \"accuracy\")\n",
    "\n",
    "print(\"Cross-validated Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3787f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7338a095",
   "metadata": {},
   "source": [
    "## Random Forest with the Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1530e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1, 3), max_features = 2000, tokenizer = word_tokenize)\n",
    "X = tfidf.fit_transform(ml[\"cleaned_text\"])\n",
    "y = ml[\"sentiment_ml\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b5a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predicted_rf = rf.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, predicted_rf)\n",
    "print('Accuracy:', accuracy_rf)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Accuracy on Training Set:\", accuracy_train)\n",
    "print(\"Accuracy on Test Set:\", accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 12)\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv = kfold, scoring = \"accuracy\")\n",
    "\n",
    "print(\"Cross-validated Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
