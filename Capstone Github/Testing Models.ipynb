{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96230404",
   "metadata": {},
   "source": [
    "# Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5ca7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf86a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns \n",
    "\n",
    "sns.set(color_codes = True)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "import emoji\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from nltk.probability import *\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from afinn import Afinn\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.text import Text\n",
    "\n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1c06ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = pd.read_csv(\"ml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1fff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.dropna(subset = [\"cleaned_text\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92be2bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starRating</th>\n",
       "      <th>Gender_Numeric</th>\n",
       "      <th>Year</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_ml</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>good</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      starRating  Gender_Numeric  Year cleaned_text  sentiment_score  \\\n",
       "1647           5               1  2018         good              0.7   \n",
       "\n",
       "      word_count  avg_word sentiment_label  sentiment_ml  sentiment  \n",
       "1647           1       4.0        Positive             2          0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca2b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913dce02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d96a938a",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a882f74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ngram_range: (1, 1)\n",
      "RF: Mean Accuracy - 0.8412, Std. Deviation - 0.0313\n",
      "MNB: Mean Accuracy - 0.7892, Std. Deviation - 0.0236\n",
      "XGB: Mean Accuracy - 0.8547, Std. Deviation - 0.0384\n",
      "LR: Mean Accuracy - 0.8561, Std. Deviation - 0.0330\n",
      "LSVC: Mean Accuracy - 0.8601, Std. Deviation - 0.0343\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.79      0.87      0.83        70\n",
      "           2       0.90      0.89      0.89        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.63      0.66       165\n",
      "weighted avg       0.86      0.85      0.84       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.80      0.61      0.69        70\n",
      "           2       0.75      0.94      0.83        88\n",
      "\n",
      "    accuracy                           0.76       165\n",
      "   macro avg       0.51      0.52      0.51       165\n",
      "weighted avg       0.74      0.76      0.74       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73         7\n",
      "           1       0.85      0.87      0.86        70\n",
      "           2       0.90      0.91      0.90        88\n",
      "\n",
      "    accuracy                           0.88       165\n",
      "   macro avg       0.92      0.78      0.83       165\n",
      "weighted avg       0.88      0.88      0.88       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.84      0.80      0.82        70\n",
      "           2       0.85      0.93      0.89        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.62      0.65       165\n",
      "weighted avg       0.85      0.84      0.83       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60         7\n",
      "           1       0.86      0.79      0.82        70\n",
      "           2       0.84      0.93      0.88        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.72      0.77       165\n",
      "weighted avg       0.85      0.85      0.84       165\n",
      "\n",
      "\n",
      "Testing ngram_range: (1, 2)\n",
      "RF: Mean Accuracy - 0.8324, Std. Deviation - 0.0391\n",
      "MNB: Mean Accuracy - 0.7939, Std. Deviation - 0.0279\n",
      "XGB: Mean Accuracy - 0.8426, Std. Deviation - 0.0465\n",
      "LR: Mean Accuracy - 0.8439, Std. Deviation - 0.0301\n",
      "LSVC: Mean Accuracy - 0.8561, Std. Deviation - 0.0299\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.80      0.86      0.83        70\n",
      "           2       0.89      0.90      0.89        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.63      0.66       165\n",
      "weighted avg       0.86      0.85      0.84       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.80      0.63      0.70        70\n",
      "           2       0.75      0.94      0.84        88\n",
      "\n",
      "    accuracy                           0.77       165\n",
      "   macro avg       0.52      0.52      0.51       165\n",
      "weighted avg       0.74      0.77      0.75       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73         7\n",
      "           1       0.84      0.81      0.83        70\n",
      "           2       0.86      0.91      0.88        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.76      0.81       165\n",
      "weighted avg       0.86      0.85      0.85       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.83      0.81      0.82        70\n",
      "           2       0.85      0.92      0.89        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.63      0.65       165\n",
      "weighted avg       0.85      0.84      0.83       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.83      0.79      0.81        70\n",
      "           2       0.84      0.92      0.88        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.66      0.71       165\n",
      "weighted avg       0.84      0.84      0.83       165\n",
      "\n",
      "\n",
      "Testing ngram_range: (1, 3)\n",
      "RF: Mean Accuracy - 0.8236, Std. Deviation - 0.0369\n",
      "MNB: Mean Accuracy - 0.7953, Std. Deviation - 0.0282\n",
      "XGB: Mean Accuracy - 0.8412, Std. Deviation - 0.0486\n",
      "LR: Mean Accuracy - 0.8453, Std. Deviation - 0.0323\n",
      "LSVC: Mean Accuracy - 0.8568, Std. Deviation - 0.0317\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.78      0.87      0.82        70\n",
      "           2       0.90      0.88      0.89        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.63      0.65       165\n",
      "weighted avg       0.85      0.84      0.83       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.80      0.63      0.70        70\n",
      "           2       0.75      0.94      0.84        88\n",
      "\n",
      "    accuracy                           0.77       165\n",
      "   macro avg       0.52      0.52      0.51       165\n",
      "weighted avg       0.74      0.77      0.75       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73         7\n",
      "           1       0.82      0.84      0.83        70\n",
      "           2       0.88      0.89      0.88        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.77      0.81       165\n",
      "weighted avg       0.86      0.85      0.85       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.83      0.81      0.82        70\n",
      "           2       0.85      0.92      0.89        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.63      0.65       165\n",
      "weighted avg       0.85      0.84      0.83       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.84      0.80      0.82        70\n",
      "           2       0.84      0.92      0.88        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.67      0.71       165\n",
      "weighted avg       0.85      0.84      0.84       165\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, \n",
    "                                                    random_state = 12, stratify = y)\n",
    "\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3)]\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    print(f\"Testing ngram_range: {ngram_range}\")\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range = ngram_range, max_features = 500, tokenizer = word_tokenize)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    models = [\n",
    "        ('RF', RandomForestClassifier()),\n",
    "        ('MNB', MultinomialNB()),\n",
    "        ('XGB', XGBClassifier()),\n",
    "        ('LR', LogisticRegression(max_iter = 500)),\n",
    "        ('LSVC', LinearSVC())\n",
    "    ]\n",
    "\n",
    "    class_reports = {}\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits = 10, random_state = 12, shuffle = True)\n",
    "        cv_results = cross_val_score(model, X_train_tfidf, y_train, cv = kfold, scoring = 'accuracy')\n",
    "        print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        class_reports[name] = classification_report(y_test, y_pred)\n",
    "\n",
    "    for name, report in class_reports.items():\n",
    "        print(f\"\\nClassification Report for {name}:\\n{report}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07bb3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ee91b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efb8b4cd",
   "metadata": {},
   "source": [
    "# Test Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c187b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing test_size: 0.1\n",
      "RF: Mean Accuracy - 0.8338, Std. Deviation - 0.0320\n",
      "MNB: Mean Accuracy - 0.7892, Std. Deviation - 0.0236\n",
      "XGB: Mean Accuracy - 0.8547, Std. Deviation - 0.0384\n",
      "LR: Mean Accuracy - 0.8561, Std. Deviation - 0.0330\n",
      "LSVC: Mean Accuracy - 0.8601, Std. Deviation - 0.0343\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.79      0.90      0.84        70\n",
      "           2       0.92      0.88      0.90        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.64      0.66       165\n",
      "weighted avg       0.87      0.85      0.84       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.80      0.61      0.69        70\n",
      "           2       0.75      0.94      0.83        88\n",
      "\n",
      "    accuracy                           0.76       165\n",
      "   macro avg       0.51      0.52      0.51       165\n",
      "weighted avg       0.74      0.76      0.74       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73         7\n",
      "           1       0.85      0.87      0.86        70\n",
      "           2       0.90      0.91      0.90        88\n",
      "\n",
      "    accuracy                           0.88       165\n",
      "   macro avg       0.92      0.78      0.83       165\n",
      "weighted avg       0.88      0.88      0.88       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.84      0.80      0.82        70\n",
      "           2       0.85      0.93      0.89        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.62      0.65       165\n",
      "weighted avg       0.85      0.84      0.83       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60         7\n",
      "           1       0.86      0.79      0.82        70\n",
      "           2       0.84      0.93      0.88        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.72      0.77       165\n",
      "weighted avg       0.85      0.85      0.84       165\n",
      "\n",
      "\n",
      "Testing test_size: 0.2\n",
      "RF: Mean Accuracy - 0.8260, Std. Deviation - 0.0182\n",
      "MNB: Mean Accuracy - 0.7918, Std. Deviation - 0.0342\n",
      "XGB: Mean Accuracy - 0.8564, Std. Deviation - 0.0200\n",
      "LR: Mean Accuracy - 0.8473, Std. Deviation - 0.0258\n",
      "LSVC: Mean Accuracy - 0.8534, Std. Deviation - 0.0201\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25        14\n",
      "           1       0.80      0.93      0.86       140\n",
      "           2       0.94      0.89      0.91       175\n",
      "\n",
      "    accuracy                           0.87       329\n",
      "   macro avg       0.91      0.65      0.67       329\n",
      "weighted avg       0.88      0.87      0.86       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.81      0.70      0.75       140\n",
      "           2       0.79      0.94      0.86       175\n",
      "\n",
      "    accuracy                           0.80       329\n",
      "   macro avg       0.53      0.55      0.54       329\n",
      "weighted avg       0.77      0.80      0.78       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67        14\n",
      "           1       0.83      0.89      0.86       140\n",
      "           2       0.92      0.89      0.90       175\n",
      "\n",
      "    accuracy                           0.87       329\n",
      "   macro avg       0.85      0.78      0.81       329\n",
      "weighted avg       0.87      0.87      0.87       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13        14\n",
      "           1       0.80      0.86      0.83       140\n",
      "           2       0.89      0.90      0.90       175\n",
      "\n",
      "    accuracy                           0.85       329\n",
      "   macro avg       0.90      0.61      0.62       329\n",
      "weighted avg       0.86      0.85      0.84       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.43      0.55        14\n",
      "           1       0.83      0.81      0.82       140\n",
      "           2       0.86      0.90      0.88       175\n",
      "\n",
      "    accuracy                           0.84       329\n",
      "   macro avg       0.81      0.72      0.75       329\n",
      "weighted avg       0.84      0.84      0.84       329\n",
      "\n",
      "\n",
      "Testing test_size: 0.3\n",
      "RF: Mean Accuracy - 0.8202, Std. Deviation - 0.0140\n",
      "MNB: Mean Accuracy - 0.7750, Std. Deviation - 0.0199\n",
      "XGB: Mean Accuracy - 0.8314, Std. Deviation - 0.0175\n",
      "LR: Mean Accuracy - 0.8471, Std. Deviation - 0.0287\n",
      "LSVC: Mean Accuracy - 0.8557, Std. Deviation - 0.0331\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.09        21\n",
      "           1       0.78      0.86      0.82       210\n",
      "           2       0.89      0.88      0.88       263\n",
      "\n",
      "    accuracy                           0.84       494\n",
      "   macro avg       0.89      0.60      0.60       494\n",
      "weighted avg       0.85      0.84      0.82       494\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.79      0.66      0.72       210\n",
      "           2       0.77      0.94      0.85       263\n",
      "\n",
      "    accuracy                           0.78       494\n",
      "   macro avg       0.52      0.53      0.52       494\n",
      "weighted avg       0.75      0.78      0.76       494\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.48      0.62        21\n",
      "           1       0.83      0.85      0.84       210\n",
      "           2       0.88      0.90      0.89       263\n",
      "\n",
      "    accuracy                           0.86       494\n",
      "   macro avg       0.88      0.74      0.79       494\n",
      "weighted avg       0.86      0.86      0.86       494\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.79      0.86      0.82       210\n",
      "           2       0.89      0.90      0.89       263\n",
      "\n",
      "    accuracy                           0.84       494\n",
      "   macro avg       0.56      0.59      0.57       494\n",
      "weighted avg       0.81      0.84      0.83       494\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.29      0.39        21\n",
      "           1       0.82      0.83      0.82       210\n",
      "           2       0.88      0.91      0.89       263\n",
      "\n",
      "    accuracy                           0.85       494\n",
      "   macro avg       0.77      0.67      0.70       494\n",
      "weighted avg       0.84      0.85      0.84       494\n",
      "\n",
      "\n",
      "Testing test_size: 0.4\n",
      "RF: Mean Accuracy - 0.8145, Std. Deviation - 0.0467\n",
      "MNB: Mean Accuracy - 0.7710, Std. Deviation - 0.0468\n",
      "XGB: Mean Accuracy - 0.8176, Std. Deviation - 0.0387\n",
      "LR: Mean Accuracy - 0.8268, Std. Deviation - 0.0494\n",
      "LSVC: Mean Accuracy - 0.8378, Std. Deviation - 0.0411\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.07      0.13        28\n",
      "           1       0.78      0.90      0.84       280\n",
      "           2       0.92      0.86      0.89       350\n",
      "\n",
      "    accuracy                           0.85       658\n",
      "   macro avg       0.79      0.61      0.62       658\n",
      "weighted avg       0.85      0.85      0.83       658\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.83      0.68      0.75       280\n",
      "           2       0.78      0.96      0.86       350\n",
      "\n",
      "    accuracy                           0.80       658\n",
      "   macro avg       0.54      0.55      0.54       658\n",
      "weighted avg       0.77      0.80      0.78       658\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.50      0.58        28\n",
      "           1       0.83      0.86      0.84       280\n",
      "           2       0.90      0.89      0.90       350\n",
      "\n",
      "    accuracy                           0.86       658\n",
      "   macro avg       0.81      0.75      0.77       658\n",
      "weighted avg       0.86      0.86      0.86       658\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.07        28\n",
      "           1       0.78      0.87      0.82       280\n",
      "           2       0.89      0.88      0.88       350\n",
      "\n",
      "    accuracy                           0.84       658\n",
      "   macro avg       0.89      0.59      0.59       658\n",
      "weighted avg       0.85      0.84      0.82       658\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.25      0.35        28\n",
      "           1       0.82      0.84      0.83       280\n",
      "           2       0.88      0.90      0.89       350\n",
      "\n",
      "    accuracy                           0.85       658\n",
      "   macro avg       0.76      0.66      0.69       658\n",
      "weighted avg       0.84      0.85      0.84       658\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "\n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "ngram_range = (1, 1)\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    print(f\"Testing test_size: {test_size}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, \n",
    "                                                        random_state = 12, stratify = y)\n",
    "\n",
    "    tfidf = TfidfVectorizer(ngram_range = ngram_range, max_features = 500, tokenizer = word_tokenize)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    models = [\n",
    "        ('RF', RandomForestClassifier()),\n",
    "        ('MNB', MultinomialNB()),\n",
    "        ('XGB', XGBClassifier()),\n",
    "        ('LR', LogisticRegression(max_iter = 500)),\n",
    "        ('LSVC', LinearSVC())\n",
    "    ]\n",
    "\n",
    "    class_reports = {}\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits = 10, random_state = 12, shuffle = True)\n",
    "        cv_results = cross_val_score(model, X_train_tfidf, y_train, cv = kfold, scoring = 'accuracy')\n",
    "        print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        class_reports[name] = classification_report(y_test, y_pred)\n",
    "\n",
    "    for name, report in class_reports.items():\n",
    "        print(f\"\\nClassification Report for {name}:\\n{report}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b578a",
   "metadata": {},
   "source": [
    "# Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e572e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.7132, Std. Deviation - 0.0630\n",
      "MNB: Mean Accuracy - 0.6574, Std. Deviation - 0.1328\n",
      "XGB: Mean Accuracy - 0.7182, Std. Deviation - 0.0558\n",
      "LR: Mean Accuracy - 0.6826, Std. Deviation - 0.0395\n",
      "LSVC: Mean Accuracy - 0.6405, Std. Deviation - 0.0627\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.57      0.42         7\n",
      "           1       0.63      0.74      0.68        70\n",
      "           2       0.83      0.67      0.74        88\n",
      "\n",
      "    accuracy                           0.70       165\n",
      "   macro avg       0.60      0.66      0.62       165\n",
      "weighted avg       0.73      0.70      0.70       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.71      0.48         7\n",
      "           1       0.82      0.46      0.59        70\n",
      "           2       0.72      0.92      0.81        88\n",
      "\n",
      "    accuracy                           0.72       165\n",
      "   macro avg       0.63      0.70      0.62       165\n",
      "weighted avg       0.75      0.72      0.70       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.57      0.36         7\n",
      "           1       0.70      0.66      0.68        70\n",
      "           2       0.79      0.75      0.77        88\n",
      "\n",
      "    accuracy                           0.70       165\n",
      "   macro avg       0.58      0.66      0.60       165\n",
      "weighted avg       0.73      0.70      0.71       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.86      0.48         7\n",
      "           1       0.80      0.59      0.68        70\n",
      "           2       0.79      0.86      0.83        88\n",
      "\n",
      "    accuracy                           0.75       165\n",
      "   macro avg       0.64      0.77      0.66       165\n",
      "weighted avg       0.78      0.75      0.75       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.57      0.36         7\n",
      "           1       0.75      0.61      0.68        70\n",
      "           2       0.77      0.82      0.80        88\n",
      "\n",
      "    accuracy                           0.72       165\n",
      "   macro avg       0.60      0.67      0.61       165\n",
      "weighted avg       0.74      0.72      0.73       165\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 12, stratify = y)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 1), max_features = 500, tokenizer = word_tokenize)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "nr = NearMiss()\n",
    "X_train_nm, y_train_nm = nr.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "models = [\n",
    "    ('RF', RandomForestClassifier()),\n",
    "    ('MNB', MultinomialNB()),\n",
    "    ('XGB', XGBClassifier()),\n",
    "    ('LR', LogisticRegression(max_iter = 500)),\n",
    "    ('LSVC', LinearSVC())\n",
    "]\n",
    "\n",
    "\n",
    "class_reports = {}\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 10, random_state = 12, shuffle = True)\n",
    "    cv_results = cross_val_score(model, X_train_nm, y_train_nm, cv = kfold, scoring = 'accuracy')\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    \n",
    "    model.fit(X_train_nm, y_train_nm)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    class_reports[name] = classification_report(y_test, y_pred)\n",
    "\n",
    "for name, report in class_reports.items():\n",
    "    print(f\"\\nClassification Report for {name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e5f48a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "478f15d2",
   "metadata": {},
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35e0b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.6926, Std. Deviation - 0.0669\n",
      "MNB: Mean Accuracy - 0.6574, Std. Deviation - 0.1328\n",
      "XGB: Mean Accuracy - 0.7182, Std. Deviation - 0.0558\n",
      "LR: Mean Accuracy - 0.6826, Std. Deviation - 0.0395\n",
      "LSVC: Mean Accuracy - 0.6405, Std. Deviation - 0.0627\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.57      0.44         7\n",
      "           1       0.68      0.67      0.68        70\n",
      "           2       0.81      0.78      0.80        88\n",
      "\n",
      "    accuracy                           0.73       165\n",
      "   macro avg       0.62      0.68      0.64       165\n",
      "weighted avg       0.74      0.73      0.73       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.71      0.48         7\n",
      "           1       0.82      0.46      0.59        70\n",
      "           2       0.72      0.92      0.81        88\n",
      "\n",
      "    accuracy                           0.72       165\n",
      "   macro avg       0.63      0.70      0.62       165\n",
      "weighted avg       0.75      0.72      0.70       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.57      0.36         7\n",
      "           1       0.70      0.66      0.68        70\n",
      "           2       0.79      0.75      0.77        88\n",
      "\n",
      "    accuracy                           0.70       165\n",
      "   macro avg       0.58      0.66      0.60       165\n",
      "weighted avg       0.73      0.70      0.71       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.86      0.48         7\n",
      "           1       0.80      0.59      0.68        70\n",
      "           2       0.79      0.86      0.83        88\n",
      "\n",
      "    accuracy                           0.75       165\n",
      "   macro avg       0.64      0.77      0.66       165\n",
      "weighted avg       0.78      0.75      0.75       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.57      0.36         7\n",
      "           1       0.75      0.61      0.68        70\n",
      "           2       0.77      0.82      0.80        88\n",
      "\n",
      "    accuracy                           0.72       165\n",
      "   macro avg       0.60      0.67      0.61       165\n",
      "weighted avg       0.74      0.72      0.73       165\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 12, stratify = y)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 1), max_features = 500, tokenizer = word_tokenize)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "smt = SMOTE()\n",
    "X_train_s, y_train_s = nr.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "models = [\n",
    "    ('RF', RandomForestClassifier()),\n",
    "    ('MNB', MultinomialNB()),\n",
    "    ('XGB', XGBClassifier()),\n",
    "    ('LR', LogisticRegression(max_iter = 500)),\n",
    "    ('LSVC', LinearSVC())\n",
    "]\n",
    "\n",
    "\n",
    "class_reports = {}\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 10, random_state = 12, shuffle = True)\n",
    "    cv_results = cross_val_score(model, X_train_s, y_train_s, cv = kfold, scoring = 'accuracy')\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    \n",
    "    model.fit(X_train_nm, y_train_nm)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    class_reports[name] = classification_report(y_test, y_pred)\n",
    "\n",
    "for name, report in class_reports.items():\n",
    "    print(f\"\\nClassification Report for {name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a21a872d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starRating</th>\n",
       "      <th>Gender_Numeric</th>\n",
       "      <th>Year</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_ml</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>good</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      starRating  Gender_Numeric  Year cleaned_text  sentiment_score  \\\n",
       "1647           5               1  2018         good              0.7   \n",
       "\n",
       "      word_count  avg_word sentiment_label  sentiment_ml  sentiment  \n",
       "1647           1       4.0        Positive             2          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dba64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "187d9d70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ngram_range: (1, 1)\n",
      "RF: Mean Accuracy - 0.8399, Std. Deviation - 0.0385\n",
      "MNB: Mean Accuracy - 0.7892, Std. Deviation - 0.0236\n",
      "XGB: Mean Accuracy - 0.8547, Std. Deviation - 0.0384\n",
      "LR: Mean Accuracy - 0.8561, Std. Deviation - 0.0330\n",
      "LSVC: Mean Accuracy - 0.8601, Std. Deviation - 0.0343\n",
      "KNN: Mean Accuracy - 0.6101, Std. Deviation - 0.0877\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.80      0.87      0.84        70\n",
      "           2       0.90      0.89      0.89        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.68      0.72       165\n",
      "weighted avg       0.86      0.85      0.85       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.80      0.61      0.69        70\n",
      "           2       0.75      0.94      0.83        88\n",
      "\n",
      "    accuracy                           0.76       165\n",
      "   macro avg       0.51      0.52      0.51       165\n",
      "weighted avg       0.74      0.76      0.74       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73         7\n",
      "           1       0.85      0.87      0.86        70\n",
      "           2       0.90      0.91      0.90        88\n",
      "\n",
      "    accuracy                           0.88       165\n",
      "   macro avg       0.92      0.78      0.83       165\n",
      "weighted avg       0.88      0.88      0.88       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.84      0.80      0.82        70\n",
      "           2       0.85      0.93      0.89        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.62      0.65       165\n",
      "weighted avg       0.85      0.84      0.83       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60         7\n",
      "           1       0.86      0.79      0.82        70\n",
      "           2       0.84      0.93      0.88        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.72      0.77       165\n",
      "weighted avg       0.85      0.85      0.84       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.57      0.18         7\n",
      "           1       0.63      0.46      0.53        70\n",
      "           2       0.82      0.70      0.76        88\n",
      "\n",
      "    accuracy                           0.59       165\n",
      "   macro avg       0.52      0.58      0.49       165\n",
      "weighted avg       0.71      0.59      0.64       165\n",
      "\n",
      "\n",
      "Testing ngram_range: (1, 2)\n",
      "RF: Mean Accuracy - 0.8311, Std. Deviation - 0.0382\n",
      "MNB: Mean Accuracy - 0.7939, Std. Deviation - 0.0279\n",
      "XGB: Mean Accuracy - 0.8426, Std. Deviation - 0.0465\n",
      "LR: Mean Accuracy - 0.8439, Std. Deviation - 0.0301\n",
      "LSVC: Mean Accuracy - 0.8561, Std. Deviation - 0.0299\n",
      "KNN: Mean Accuracy - 0.5980, Std. Deviation - 0.0757\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.80      0.87      0.84        70\n",
      "           2       0.90      0.90      0.90        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.64      0.66       165\n",
      "weighted avg       0.86      0.85      0.84       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.80      0.63      0.70        70\n",
      "           2       0.75      0.94      0.84        88\n",
      "\n",
      "    accuracy                           0.77       165\n",
      "   macro avg       0.52      0.52      0.51       165\n",
      "weighted avg       0.74      0.77      0.75       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73         7\n",
      "           1       0.84      0.81      0.83        70\n",
      "           2       0.86      0.91      0.88        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.76      0.81       165\n",
      "weighted avg       0.86      0.85      0.85       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.83      0.81      0.82        70\n",
      "           2       0.85      0.92      0.89        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.63      0.65       165\n",
      "weighted avg       0.85      0.84      0.83       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.83      0.79      0.81        70\n",
      "           2       0.84      0.92      0.88        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.66      0.71       165\n",
      "weighted avg       0.84      0.84      0.83       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.71      0.20         7\n",
      "           1       0.65      0.44      0.53        70\n",
      "           2       0.84      0.72      0.77        88\n",
      "\n",
      "    accuracy                           0.60       165\n",
      "   macro avg       0.53      0.62      0.50       165\n",
      "weighted avg       0.73      0.60      0.64       165\n",
      "\n",
      "\n",
      "Testing ngram_range: (1, 3)\n",
      "RF: Mean Accuracy - 0.8270, Std. Deviation - 0.0390\n",
      "MNB: Mean Accuracy - 0.7953, Std. Deviation - 0.0282\n",
      "XGB: Mean Accuracy - 0.8412, Std. Deviation - 0.0486\n",
      "LR: Mean Accuracy - 0.8453, Std. Deviation - 0.0323\n",
      "LSVC: Mean Accuracy - 0.8568, Std. Deviation - 0.0317\n",
      "KNN: Mean Accuracy - 0.6020, Std. Deviation - 0.0756\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.80      0.87      0.84        70\n",
      "           2       0.90      0.90      0.90        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.64      0.66       165\n",
      "weighted avg       0.86      0.85      0.84       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.80      0.63      0.70        70\n",
      "           2       0.75      0.94      0.84        88\n",
      "\n",
      "    accuracy                           0.77       165\n",
      "   macro avg       0.52      0.52      0.51       165\n",
      "weighted avg       0.74      0.77      0.75       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73         7\n",
      "           1       0.82      0.84      0.83        70\n",
      "           2       0.88      0.89      0.88        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.77      0.81       165\n",
      "weighted avg       0.86      0.85      0.85       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.83      0.81      0.82        70\n",
      "           2       0.85      0.92      0.89        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.63      0.65       165\n",
      "weighted avg       0.85      0.84      0.83       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.84      0.80      0.82        70\n",
      "           2       0.84      0.92      0.88        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.89      0.67      0.71       165\n",
      "weighted avg       0.85      0.84      0.84       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.86      0.24         7\n",
      "           1       0.60      0.43      0.50        70\n",
      "           2       0.84      0.69      0.76        88\n",
      "\n",
      "    accuracy                           0.59       165\n",
      "   macro avg       0.53      0.66      0.50       165\n",
      "weighted avg       0.71      0.59      0.63       165\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, \n",
    "                                                    random_state = 12, stratify = y)\n",
    "\n",
    "ngram_ranges = [(1, 1), (1, 2), (1, 3)]\n",
    "\n",
    "for ngram_range in ngram_ranges:\n",
    "    print(f\"Testing ngram_range: {ngram_range}\")\n",
    "    \n",
    "    tfidf = TfidfVectorizer(ngram_range=ngram_range, max_features = 500, tokenizer = word_tokenize)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    models = [\n",
    "        ('RF', RandomForestClassifier()),\n",
    "        ('MNB', MultinomialNB()),\n",
    "        ('XGB', XGBClassifier()),\n",
    "        ('LR', LogisticRegression(max_iter = 500)),\n",
    "        ('LSVC', LinearSVC()),\n",
    "        (\"KNN\", KNeighborsClassifier())\n",
    "    ]\n",
    "\n",
    "    class_reports = {}\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits = 10, random_state = 12, shuffle = True)\n",
    "        cv_results = cross_val_score(model, X_train_tfidf, y_train, cv = kfold, scoring = 'accuracy')\n",
    "        print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        class_reports[name] = classification_report(y_test, y_pred)\n",
    "\n",
    "    for name, report in class_reports.items():\n",
    "        print(f\"\\nClassification Report for {name}:\\n{report}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b385b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8c642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb328894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd1343b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing test_size: 0.1\n",
      "RF: Mean Accuracy - 0.8412, Std. Deviation - 0.0326\n",
      "MNB: Mean Accuracy - 0.7750, Std. Deviation - 0.0287\n",
      "XGB: Mean Accuracy - 0.8601, Std. Deviation - 0.0414\n",
      "LR: Mean Accuracy - 0.8547, Std. Deviation - 0.0295\n",
      "LSVC: Mean Accuracy - 0.8561, Std. Deviation - 0.0284\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.81      0.83      0.82        70\n",
      "           2       0.87      0.92      0.90        88\n",
      "\n",
      "    accuracy                           0.84       165\n",
      "   macro avg       0.56      0.58      0.57       165\n",
      "weighted avg       0.81      0.84      0.82       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.82      0.59      0.68        70\n",
      "           2       0.73      0.95      0.83        88\n",
      "\n",
      "    accuracy                           0.76       165\n",
      "   macro avg       0.52      0.51      0.50       165\n",
      "weighted avg       0.74      0.76      0.73       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.73         7\n",
      "           1       0.83      0.84      0.84        70\n",
      "           2       0.88      0.90      0.89        88\n",
      "\n",
      "    accuracy                           0.86       165\n",
      "   macro avg       0.90      0.77      0.82       165\n",
      "weighted avg       0.86      0.86      0.86       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25         7\n",
      "           1       0.83      0.84      0.84        70\n",
      "           2       0.88      0.93      0.91        88\n",
      "\n",
      "    accuracy                           0.86       165\n",
      "   macro avg       0.90      0.64      0.66       165\n",
      "weighted avg       0.87      0.86      0.85       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.85      0.81      0.83        70\n",
      "           2       0.85      0.93      0.89        88\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.90      0.68      0.72       165\n",
      "weighted avg       0.86      0.85      0.85       165\n",
      "\n",
      "\n",
      "Testing test_size: 0.2\n",
      "RF: Mean Accuracy - 0.8290, Std. Deviation - 0.0177\n",
      "MNB: Mean Accuracy - 0.7674, Std. Deviation - 0.0255\n",
      "XGB: Mean Accuracy - 0.8526, Std. Deviation - 0.0225\n",
      "LR: Mean Accuracy - 0.8450, Std. Deviation - 0.0236\n",
      "LSVC: Mean Accuracy - 0.8610, Std. Deviation - 0.0181\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25        14\n",
      "           1       0.81      0.91      0.86       140\n",
      "           2       0.93      0.89      0.91       175\n",
      "\n",
      "    accuracy                           0.87       329\n",
      "   macro avg       0.91      0.65      0.67       329\n",
      "weighted avg       0.88      0.87      0.86       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.84      0.68      0.75       140\n",
      "           2       0.78      0.97      0.86       175\n",
      "\n",
      "    accuracy                           0.80       329\n",
      "   macro avg       0.54      0.55      0.54       329\n",
      "weighted avg       0.77      0.80      0.78       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        14\n",
      "           1       0.85      0.86      0.86       140\n",
      "           2       0.91      0.91      0.91       175\n",
      "\n",
      "    accuracy                           0.88       329\n",
      "   macro avg       0.81      0.78      0.79       329\n",
      "weighted avg       0.87      0.88      0.87       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.79      0.88      0.83       140\n",
      "           2       0.90      0.90      0.90       175\n",
      "\n",
      "    accuracy                           0.85       329\n",
      "   macro avg       0.57      0.59      0.58       329\n",
      "weighted avg       0.82      0.85      0.83       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.36      0.50        14\n",
      "           1       0.82      0.83      0.82       140\n",
      "           2       0.87      0.90      0.88       175\n",
      "\n",
      "    accuracy                           0.84       329\n",
      "   macro avg       0.84      0.69      0.73       329\n",
      "weighted avg       0.84      0.84      0.84       329\n",
      "\n",
      "\n",
      "Testing test_size: 0.3\n",
      "RF: Mean Accuracy - 0.8314, Std. Deviation - 0.0207\n",
      "MNB: Mean Accuracy - 0.7550, Std. Deviation - 0.0150\n",
      "XGB: Mean Accuracy - 0.8427, Std. Deviation - 0.0253\n",
      "LR: Mean Accuracy - 0.8402, Std. Deviation - 0.0226\n",
      "LSVC: Mean Accuracy - 0.8566, Std. Deviation - 0.0172\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.17        21\n",
      "           1       0.80      0.84      0.82       210\n",
      "           2       0.88      0.90      0.89       263\n",
      "\n",
      "    accuracy                           0.84       494\n",
      "   macro avg       0.89      0.61      0.63       494\n",
      "weighted avg       0.85      0.84      0.83       494\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.82      0.63      0.71       210\n",
      "           2       0.76      0.96      0.85       263\n",
      "\n",
      "    accuracy                           0.78       494\n",
      "   macro avg       0.53      0.53      0.52       494\n",
      "weighted avg       0.75      0.78      0.75       494\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.43      0.55        21\n",
      "           1       0.82      0.85      0.84       210\n",
      "           2       0.89      0.90      0.89       263\n",
      "\n",
      "    accuracy                           0.86       494\n",
      "   macro avg       0.82      0.72      0.76       494\n",
      "weighted avg       0.85      0.86      0.85       494\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        21\n",
      "           1       0.79      0.88      0.83       210\n",
      "           2       0.90      0.89      0.90       263\n",
      "\n",
      "    accuracy                           0.85       494\n",
      "   macro avg       0.56      0.59      0.58       494\n",
      "weighted avg       0.82      0.85      0.83       494\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.38        21\n",
      "           1       0.81      0.85      0.83       210\n",
      "           2       0.88      0.90      0.89       263\n",
      "\n",
      "    accuracy                           0.85       494\n",
      "   macro avg       0.90      0.66      0.70       494\n",
      "weighted avg       0.86      0.85      0.84       494\n",
      "\n",
      "\n",
      "Testing test_size: 0.4\n",
      "RF: Mean Accuracy - 0.8156, Std. Deviation - 0.0386\n",
      "MNB: Mean Accuracy - 0.7345, Std. Deviation - 0.0423\n",
      "XGB: Mean Accuracy - 0.8257, Std. Deviation - 0.0369\n",
      "LR: Mean Accuracy - 0.8349, Std. Deviation - 0.0482\n",
      "LSVC: Mean Accuracy - 0.8399, Std. Deviation - 0.0327\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.07        28\n",
      "           1       0.76      0.86      0.80       280\n",
      "           2       0.88      0.85      0.86       350\n",
      "\n",
      "    accuracy                           0.82       658\n",
      "   macro avg       0.88      0.58      0.58       658\n",
      "weighted avg       0.83      0.82      0.80       658\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.82      0.65      0.73       280\n",
      "           2       0.77      0.96      0.85       350\n",
      "\n",
      "    accuracy                           0.79       658\n",
      "   macro avg       0.53      0.54      0.53       658\n",
      "weighted avg       0.76      0.79      0.76       658\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.39      0.54        28\n",
      "           1       0.81      0.87      0.84       280\n",
      "           2       0.90      0.89      0.89       350\n",
      "\n",
      "    accuracy                           0.86       658\n",
      "   macro avg       0.85      0.72      0.76       658\n",
      "weighted avg       0.86      0.86      0.85       658\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.78      0.88      0.82       280\n",
      "           2       0.89      0.87      0.88       350\n",
      "\n",
      "    accuracy                           0.84       658\n",
      "   macro avg       0.56      0.58      0.57       658\n",
      "weighted avg       0.81      0.84      0.82       658\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.18      0.29        28\n",
      "           1       0.81      0.86      0.83       280\n",
      "           2       0.88      0.90      0.89       350\n",
      "\n",
      "    accuracy                           0.85       658\n",
      "   macro avg       0.84      0.64      0.67       658\n",
      "weighted avg       0.85      0.85      0.84       658\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "\n",
    "test_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "ngram_range = (1, 1)\n",
    "\n",
    "for test_size in test_sizes:\n",
    "    print(f\"Testing test_size: {test_size}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, \n",
    "                                                        random_state = 12, stratify = y)\n",
    "\n",
    "    tfidf = TfidfVectorizer(ngram_range = ngram_range, max_features = 2000, tokenizer = word_tokenize)\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    models = [\n",
    "        ('RF', RandomForestClassifier()),\n",
    "        ('MNB', MultinomialNB()),\n",
    "        ('XGB', XGBClassifier()),\n",
    "        ('LR', LogisticRegression(max_iter = 500)),\n",
    "        ('LSVC', LinearSVC())\n",
    "    ]\n",
    "\n",
    "    class_reports = {}\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits = 10, random_state = 12, shuffle = True)\n",
    "        cv_results = cross_val_score(model, X_train_tfidf, y_train, cv = kfold, scoring = 'accuracy')\n",
    "        print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        class_reports[name] = classification_report(y_test, y_pred)\n",
    "\n",
    "    for name, report in class_reports.items():\n",
    "        print(f\"\\nClassification Report for {name}:\\n{report}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725f7f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
