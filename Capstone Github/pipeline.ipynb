{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43390685",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eadb6147",
   "metadata": {},
   "source": [
    "# Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4bfba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47845496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns \n",
    "\n",
    "sns.set(color_codes = True)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from textblob import Word\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "import emoji\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from nltk.probability import *\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from afinn import Afinn\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.text import Text\n",
    "\n",
    "\n",
    "import string\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc55ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27200250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install genderize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e4ffa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gender-guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f67bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6425b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0a1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e25f791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6128f34",
   "metadata": {},
   "source": [
    "### Color Pallete Brand Kit\n",
    "\n",
    "\"#ff914d\"  -- Orange\n",
    "\"#1a562a\"  -- Green"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96e66e7",
   "metadata": {},
   "source": [
    "# Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d52cb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = pd.read_csv(\"ml.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "486af94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>starRating</th>\n",
       "      <th>Gender_Numeric</th>\n",
       "      <th>Year</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_ml</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>im every beginning year highly recommend chale...</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>11</td>\n",
       "      <td>6.272727</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>beautiful pleasant place breakfast lunch lot v...</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>8</td>\n",
       "      <td>6.875000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>thought horrible location much many demand own...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>15</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>one best canpings region</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>family place found thing site expensive like l...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   starRating  Gender_Numeric  Year  \\\n",
       "0           5               1  2019   \n",
       "1           5               2  2019   \n",
       "2           1               2  2019   \n",
       "3           5               1  2019   \n",
       "4           5               1  2019   \n",
       "\n",
       "                                        cleaned_text  sentiment_score  \\\n",
       "0  im every beginning year highly recommend chale...         0.030000   \n",
       "1  beautiful pleasant place breakfast lunch lot v...         0.861111   \n",
       "2  thought horrible location much many demand own...        -0.050000   \n",
       "3                           one best canpings region         1.000000   \n",
       "4  family place found thing site expensive like l...        -0.500000   \n",
       "\n",
       "   word_count  avg_word sentiment_label  sentiment_ml  sentiment  \n",
       "0          11  6.272727         Neutral             1          0  \n",
       "1           8  6.875000        Positive             2          0  \n",
       "2          15  5.466667        Negative             0          0  \n",
       "3           4  5.250000        Positive             2          0  \n",
       "4          12  5.416667        Negative             0          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c0b0617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1648 entries, 0 to 1647\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   starRating       1648 non-null   int64  \n",
      " 1   Gender_Numeric   1648 non-null   int64  \n",
      " 2   Year             1648 non-null   int64  \n",
      " 3   cleaned_text     1645 non-null   object \n",
      " 4   sentiment_score  1648 non-null   float64\n",
      " 5   word_count       1648 non-null   int64  \n",
      " 6   avg_word         1648 non-null   float64\n",
      " 7   sentiment_label  1648 non-null   object \n",
      " 8   sentiment_ml     1648 non-null   int64  \n",
      " 9   sentiment        1648 non-null   int64  \n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 128.9+ KB\n"
     ]
    }
   ],
   "source": [
    "ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e497f639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml[\"cleaned_text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddad19c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml[\"cleaned_text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "556f6b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.dropna(subset = [\"cleaned_text\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05326921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml[\"cleaned_text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e73c71",
   "metadata": {},
   "source": [
    "# Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145b94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bbcaf3e",
   "metadata": {},
   "source": [
    "Stratified Splitting:\n",
    "\n",
    "The stratify=y argument is crucial for classification problems where you have multiple categories in your target variable y. It ensures that the proportion of classes in the training set is similar to the proportion in the entire dataset. This is important to avoid a situation where the training set might be biased towards certain classes, leading to poor model performance on the unseen test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c16539",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a2f8d05",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/cross_validation.html#stratification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a74997a",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)  # Keep all features\n",
    "X = tfidf.fit_transform(ml[\"cleaned_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8d08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1, 1), max_features = 500, tokenizer = word_tokenize)\n",
    "X = tfidf.fit_transform(ml[\"cleaned_text\"])\n",
    "y = ml[\"sentiment_ml\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, \n",
    "                                                    random_state = 12, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c58bbf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('MNB', MultinomialNB()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('LR', LogisticRegression(max_iter = 1000)))\n",
    "models.append(('LSVC', LinearSVC(random_state = 12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a48a9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.832813 (0.020497)\n",
      "MNB: 0.794795 (0.035304)\n",
      "XGB: 0.854869 (0.017760)\n",
      "LR: 0.848791 (0.024575)\n",
      "LSVC: 0.856425 (0.021318)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state = 12, shuffle = True)\n",
    "\tcv_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00a451ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.8237, Std. Deviation - 0.0240\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25        14\n",
      "           1       0.77      0.90      0.83       140\n",
      "           2       0.91      0.86      0.88       175\n",
      "\n",
      "    accuracy                           0.84       329\n",
      "   macro avg       0.90      0.63      0.66       329\n",
      "weighted avg       0.86      0.84      0.84       329\n",
      "\n",
      "\n",
      "MNB: Mean Accuracy - 0.7903, Std. Deviation - 0.0316\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.80      0.70      0.75       140\n",
      "           2       0.79      0.94      0.86       175\n",
      "\n",
      "    accuracy                           0.80       329\n",
      "   macro avg       0.53      0.55      0.54       329\n",
      "weighted avg       0.76      0.80      0.78       329\n",
      "\n",
      "\n",
      "XGB: Mean Accuracy - 0.8511, Std. Deviation - 0.0293\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.57      0.64        14\n",
      "           1       0.82      0.88      0.85       140\n",
      "           2       0.92      0.88      0.90       175\n",
      "\n",
      "    accuracy                           0.87       329\n",
      "   macro avg       0.82      0.78      0.80       329\n",
      "weighted avg       0.87      0.87      0.87       329\n",
      "\n",
      "\n",
      "LR: Mean Accuracy - 0.8473, Std. Deviation - 0.0246\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13        14\n",
      "           1       0.79      0.86      0.82       140\n",
      "           2       0.89      0.90      0.89       175\n",
      "\n",
      "    accuracy                           0.84       329\n",
      "   macro avg       0.89      0.61      0.62       329\n",
      "weighted avg       0.85      0.84      0.83       329\n",
      "\n",
      "\n",
      "LSVC: Mean Accuracy - 0.8481, Std. Deviation - 0.0265\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.43      0.55        14\n",
      "           1       0.83      0.82      0.83       140\n",
      "           2       0.87      0.91      0.89       175\n",
      "\n",
      "    accuracy                           0.85       329\n",
      "   macro avg       0.82      0.72      0.75       329\n",
      "weighted avg       0.85      0.85      0.85       329\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "class_reports = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "    model.fit(X_train, y_train)  \n",
    "    y_pred = model.predict(X_test)  \n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = \"accuracy\")\n",
    "    class_report_fold = classification_report(y_test, y_pred)\n",
    "    class_reports.append(class_report_fold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    print(f\"\\nClassification Report for {name}:\\n{class_report_fold}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b03cdbf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19edf28d",
   "metadata": {},
   "source": [
    "# Under Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc8ffeb",
   "metadata": {},
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1, 1), max_features = 500, tokenizer = word_tokenize)\n",
    "X = tfidf.fit_transform(ml[\"cleaned_text\"])\n",
    "y = ml[\"sentiment_ml\"]\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "nr = NearMiss()\n",
    "\n",
    "X_train, y_train = nr.fit_resample(X_train, y_train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, \n",
    "                                                    random_state = 12, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3face6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=12, stratify=y)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1, 1), max_features=500, tokenizer=word_tokenize)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "nr = NearMiss()\n",
    "X_train_nm, y_train_nm = nr.fit_resample(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "29f4e5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('MNB', MultinomialNB()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models.append(('LSVC', LinearSVC(random_state=12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f8b73bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.650000 (0.089646)\n",
      "MNB: 0.573856 (0.089940)\n",
      "XGB: 0.737255 (0.138704)\n",
      "LR: 0.585621 (0.120489)\n",
      "LSVC: 0.591503 (0.124706)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits = 10, random_state = 12, shuffle = True)\n",
    "\tcv_results = cross_val_score(model, X_train_nm, y_train_nm, cv = kfold, scoring = 'accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f20e47c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.6313, Std. Deviation - 0.0497\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.50      0.30        14\n",
      "           1       0.59      0.65      0.62       140\n",
      "           2       0.81      0.65      0.72       175\n",
      "\n",
      "    accuracy                           0.64       329\n",
      "   macro avg       0.54      0.60      0.55       329\n",
      "weighted avg       0.69      0.64      0.66       329\n",
      "\n",
      "\n",
      "MNB: Mean Accuracy - 0.5845, Std. Deviation - 0.0367\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.79      0.33        14\n",
      "           1       0.58      0.30      0.40       140\n",
      "           2       0.71      0.83      0.76       175\n",
      "\n",
      "    accuracy                           0.60       329\n",
      "   macro avg       0.50      0.64      0.50       329\n",
      "weighted avg       0.63      0.60      0.59       329\n",
      "\n",
      "\n",
      "XGB: Mean Accuracy - 0.7134, Std. Deviation - 0.0287\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.57      0.19        14\n",
      "           1       0.63      0.51      0.56       140\n",
      "           2       0.84      0.71      0.77       175\n",
      "\n",
      "    accuracy                           0.62       329\n",
      "   macro avg       0.53      0.60      0.51       329\n",
      "weighted avg       0.72      0.62      0.66       329\n",
      "\n",
      "\n",
      "LR: Mean Accuracy - 0.6082, Std. Deviation - 0.0507\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.86      0.42        14\n",
      "           1       0.58      0.52      0.55       140\n",
      "           2       0.75      0.69      0.72       175\n",
      "\n",
      "    accuracy                           0.62       329\n",
      "   macro avg       0.54      0.69      0.56       329\n",
      "weighted avg       0.66      0.62      0.63       329\n",
      "\n",
      "\n",
      "LSVC: Mean Accuracy - 0.5845, Std. Deviation - 0.0317\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.86      0.45        14\n",
      "           1       0.58      0.52      0.55       140\n",
      "           2       0.75      0.70      0.72       175\n",
      "\n",
      "    accuracy                           0.63       329\n",
      "   macro avg       0.55      0.69      0.58       329\n",
      "weighted avg       0.66      0.63      0.64       329\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "class_reports = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 5, random_state = 1, shuffle = True)\n",
    "    model.fit(X_train_nm, y_train_nm)  \n",
    "    y_pred = model.predict(X_test_tfidf)  \n",
    "    cv_results = cross_val_score(model, X_train_nm, y_train_nm, cv = kfold, scoring = \"accuracy\")\n",
    "    class_report_fold = classification_report(y_test, y_pred)\n",
    "    class_reports.append(class_report_fold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    print(f\"\\nClassification Report for {name}:\\n{class_report_fold}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dafe389",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfc0365a",
   "metadata": {},
   "source": [
    "# Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66523a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1, stratify = y, test_size = 0.30)\n",
    "\n",
    "smt = SMOTE()\n",
    "\n",
    "X_train, y_train = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 1), max_features = 500, tokenizer = word_tokenize)\n",
    "X = tfidf.fit_transform(ml[\"cleaned_text\"])\n",
    "y = ml[\"sentiment_ml\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, \n",
    "                                                    random_state = 12, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c4fe97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('MNB', MultinomialNB()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('LR', LogisticRegression(max_iter=1000)))\n",
    "models.append(('LSVC', LinearSVC(random_state=12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e79cce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.893273 (0.022617)\n",
      "MNB: 0.850232 (0.025954)\n",
      "XGB: 0.905236 (0.026296)\n",
      "LR: 0.895994 (0.018676)\n",
      "LSVC: 0.897081 (0.022971)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=12, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae437e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.8954, Std. Deviation - 0.0257\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57        21\n",
      "           1       0.80      0.83      0.81       210\n",
      "           2       0.90      0.86      0.88       263\n",
      "\n",
      "    accuracy                           0.84       494\n",
      "   macro avg       0.75      0.76      0.76       494\n",
      "weighted avg       0.84      0.84      0.84       494\n",
      "\n",
      "\n",
      "MNB: Mean Accuracy - 0.8540, Std. Deviation - 0.0241\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.67      0.37        21\n",
      "           1       0.76      0.64      0.70       210\n",
      "           2       0.84      0.84      0.84       263\n",
      "\n",
      "    accuracy                           0.75       494\n",
      "   macro avg       0.62      0.72      0.64       494\n",
      "weighted avg       0.78      0.75      0.76       494\n",
      "\n",
      "\n",
      "XGB: Mean Accuracy - 0.8998, Std. Deviation - 0.0297\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.38      0.42        21\n",
      "           1       0.79      0.87      0.83       210\n",
      "           2       0.92      0.87      0.89       263\n",
      "\n",
      "    accuracy                           0.85       494\n",
      "   macro avg       0.73      0.70      0.71       494\n",
      "weighted avg       0.85      0.85      0.85       494\n",
      "\n",
      "\n",
      "LR: Mean Accuracy - 0.8976, Std. Deviation - 0.0219\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.67      0.48        21\n",
      "           1       0.78      0.80      0.79       210\n",
      "           2       0.91      0.83      0.87       263\n",
      "\n",
      "    accuracy                           0.81       494\n",
      "   macro avg       0.69      0.77      0.71       494\n",
      "weighted avg       0.83      0.81      0.82       494\n",
      "\n",
      "\n",
      "LSVC: Mean Accuracy - 0.8998, Std. Deviation - 0.0169\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.71      0.51        21\n",
      "           1       0.79      0.78      0.79       210\n",
      "           2       0.90      0.85      0.87       263\n",
      "\n",
      "    accuracy                           0.81       494\n",
      "   macro avg       0.69      0.78      0.72       494\n",
      "weighted avg       0.83      0.81      0.82       494\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "class_reports = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "    model.fit(X_train, y_train)  \n",
    "    y_pred = model.predict(X_test)  \n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = \"accuracy\")\n",
    "    class_report_fold = classification_report(y_test, y_pred)\n",
    "    class_reports.append(class_report_fold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    print(f\"\\nClassification Report for {name}:\\n{class_report_fold}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db6246",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3298661",
   "metadata": {},
   "source": [
    "# n gram 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b63071cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1, 2), max_features = 500, tokenizer = word_tokenize)\n",
    "X = tfidf.fit_transform(ml[\"cleaned_text\"])\n",
    "y = ml[\"sentiment_ml\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, \n",
    "                                                    random_state = 12, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a35287f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('MNB', MultinomialNB()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('LR', LogisticRegression(max_iter = 1000)))\n",
    "models.append(('LSVC', LinearSVC(random_state = 12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "994afe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.831344 (0.024009)\n",
      "MNB: 0.786462 (0.033209)\n",
      "XGB: 0.841204 (0.027273)\n",
      "LR: 0.840458 (0.019558)\n",
      "LSVC: 0.853372 (0.018728)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state = 12, shuffle = True)\n",
    "\tcv_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81baa696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.8268, Std. Deviation - 0.0239\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.21      0.35        14\n",
      "           1       0.79      0.91      0.85       140\n",
      "           2       0.93      0.87      0.90       175\n",
      "\n",
      "    accuracy                           0.86       329\n",
      "   macro avg       0.91      0.67      0.70       329\n",
      "weighted avg       0.87      0.86      0.85       329\n",
      "\n",
      "\n",
      "MNB: Mean Accuracy - 0.7895, Std. Deviation - 0.0349\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.80      0.73      0.76       140\n",
      "           2       0.81      0.93      0.86       175\n",
      "\n",
      "    accuracy                           0.80       329\n",
      "   macro avg       0.53      0.55      0.54       329\n",
      "weighted avg       0.77      0.80      0.78       329\n",
      "\n",
      "\n",
      "XGB: Mean Accuracy - 0.8404, Std. Deviation - 0.0324\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.64      0.67        14\n",
      "           1       0.82      0.86      0.84       140\n",
      "           2       0.91      0.88      0.89       175\n",
      "\n",
      "    accuracy                           0.86       329\n",
      "   macro avg       0.81      0.79      0.80       329\n",
      "weighted avg       0.86      0.86      0.86       329\n",
      "\n",
      "\n",
      "LR: Mean Accuracy - 0.8435, Std. Deviation - 0.0200\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13        14\n",
      "           1       0.81      0.86      0.84       140\n",
      "           2       0.89      0.91      0.90       175\n",
      "\n",
      "    accuracy                           0.86       329\n",
      "   macro avg       0.90      0.62      0.62       329\n",
      "weighted avg       0.86      0.86      0.84       329\n",
      "\n",
      "\n",
      "LSVC: Mean Accuracy - 0.8472, Std. Deviation - 0.0255\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.50      0.58        14\n",
      "           1       0.84      0.84      0.84       140\n",
      "           2       0.88      0.90      0.89       175\n",
      "\n",
      "    accuracy                           0.86       329\n",
      "   macro avg       0.81      0.75      0.77       329\n",
      "weighted avg       0.85      0.86      0.86       329\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "class_reports = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "    model.fit(X_train, y_train)  \n",
    "    y_pred = model.predict(X_test)  \n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = \"accuracy\")\n",
    "    class_report_fold = classification_report(y_test, y_pred)\n",
    "    class_reports.append(class_report_fold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    print(f\"\\nClassification Report for {name}:\\n{class_report_fold}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ec304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5cb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17efb11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a91b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc049a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c1c15fa",
   "metadata": {},
   "source": [
    "# n gram 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c820c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range = (1, 3), max_features = 500, tokenizer = word_tokenize)\n",
    "X = tfidf.fit_transform(ml[\"cleaned_text\"])\n",
    "y = ml[\"sentiment_ml\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, \n",
    "                                                    random_state = 12, stratify = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "34ac4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('MNB', MultinomialNB()))\n",
    "models.append(('XGB', XGBClassifier()))\n",
    "models.append(('LR', LogisticRegression(max_iter = 1000)))\n",
    "models.append(('LSVC', LinearSVC(random_state = 12)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2d343c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.828302 (0.034108)\n",
      "MNB: 0.781905 (0.033114)\n",
      "XGB: 0.843436 (0.025020)\n",
      "LR: 0.839700 (0.020265)\n",
      "LSVC: 0.850324 (0.016501)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state = 12, shuffle = True)\n",
    "\tcv_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd924700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.8366, Std. Deviation - 0.0218\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25        14\n",
      "           1       0.78      0.89      0.83       140\n",
      "           2       0.91      0.86      0.89       175\n",
      "\n",
      "    accuracy                           0.84       329\n",
      "   macro avg       0.90      0.63      0.66       329\n",
      "weighted avg       0.86      0.84      0.84       329\n",
      "\n",
      "\n",
      "MNB: Mean Accuracy - 0.7895, Std. Deviation - 0.0367\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.79      0.71      0.75       140\n",
      "           2       0.80      0.92      0.85       175\n",
      "\n",
      "    accuracy                           0.79       329\n",
      "   macro avg       0.53      0.54      0.53       329\n",
      "weighted avg       0.76      0.79      0.77       329\n",
      "\n",
      "\n",
      "XGB: Mean Accuracy - 0.8381, Std. Deviation - 0.0316\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64        14\n",
      "           1       0.83      0.85      0.84       140\n",
      "           2       0.91      0.89      0.90       175\n",
      "\n",
      "    accuracy                           0.86       329\n",
      "   macro avg       0.79      0.79      0.79       329\n",
      "weighted avg       0.86      0.86      0.86       329\n",
      "\n",
      "\n",
      "LR: Mean Accuracy - 0.8420, Std. Deviation - 0.0163\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.07      0.13        14\n",
      "           1       0.81      0.86      0.83       140\n",
      "           2       0.89      0.91      0.90       175\n",
      "\n",
      "    accuracy                           0.85       329\n",
      "   macro avg       0.90      0.61      0.62       329\n",
      "weighted avg       0.86      0.85      0.84       329\n",
      "\n",
      "\n",
      "LSVC: Mean Accuracy - 0.8473, Std. Deviation - 0.0246\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.50      0.58        14\n",
      "           1       0.86      0.82      0.84       140\n",
      "           2       0.88      0.93      0.90       175\n",
      "\n",
      "    accuracy                           0.86       329\n",
      "   macro avg       0.81      0.75      0.77       329\n",
      "weighted avg       0.86      0.86      0.86       329\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "names = []\n",
    "class_reports = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 10, random_state = 1, shuffle = True)\n",
    "    model.fit(X_train, y_train)  \n",
    "    y_pred = model.predict(X_test)  \n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv = kfold, scoring = \"accuracy\")\n",
    "    class_report_fold = classification_report(y_test, y_pred)\n",
    "    class_reports.append(class_report_fold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    print(f\"\\nClassification Report for {name}:\\n{class_report_fold}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fa861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11397f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0cf84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f8720",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae41b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02f576ae",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1372e1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "predicted_rf = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy_rf = accuracy_score(y_test, predicted_rf)\n",
    "print('Accuracy:', accuracy_rf)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_rf))\n",
    "\n",
    "y_train_pred = rf.predict(X_train)\n",
    "\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Accuracy on Training Set:\", accuracy_train)\n",
    "print(\"Accuracy on Test Set:\", accuracy_test)\n",
    "\n",
    "# Build confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, predicted_rf)\n",
    "\n",
    "# Create heatmap\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm_rf, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('True sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef8d14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e793378c",
   "metadata": {},
   "source": [
    "## Naive Bayes Multinominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b44cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "predicted_nb = nb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print classification report \n",
    "accuracy_nb = accuracy_score(y_test, predicted_nb)\n",
    "print('Accuracy:', accuracy_nb)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_nb))\n",
    "\n",
    "\n",
    "cm_nb = confusion_matrix(y_test, predicted_nb)\n",
    "\n",
    "# Create heatmap\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm_nb, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('True sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d9ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef8b3ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22168e13",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c7c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "predicted_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print classification report \n",
    "accuracy_xgb = accuracy_score(y_test, predicted_xgb)\n",
    "print('Accuracy:', accuracy_xgb)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_xgb))\n",
    "\n",
    "cm_xgb = confusion_matrix(y_test, predicted_xgb)\n",
    "\n",
    "# Create heatmap\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm_xgb, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('True sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddfa5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6255cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d83877d",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25283fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "predicted_lr = lr.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy_lr = accuracy_score(y_test, predicted_lr)\n",
    "print('Accuracy:', accuracy_lr)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_lr))\n",
    "\n",
    "cm_lr = confusion_matrix(y_test, predicted_lr)\n",
    "\n",
    "# Create heatmap\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm_lr, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('True sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008fe97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272179c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7125fb14",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381dcf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(random_state=12)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "predicted_svc = svc.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "accuracy_svc = accuracy_score(y_test, predicted_svc)\n",
    "print('Accuracy:', accuracy_svc)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predicted_svc))\n",
    "\n",
    "\n",
    "cm_svc = confusion_matrix(y_test, predicted_svc)\n",
    "\n",
    "# Create heatmap\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "sns.heatmap(cm_svc, annot=True, cmap='Blues', fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted sentiment')\n",
    "plt.ylabel('True sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95171e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Models = ['Random Forest', 'Naive Bayes Multinominal', 'XGBoost', 'Logistic Regression', 'SVC']\n",
    "Scores = [accuracy_rf, accuracy_nb, accuracy_xgb, accuracy_lr, accuracy_svc]\n",
    "performance = pd.DataFrame(list(zip(Models, Scores)), \n",
    "                          columns = ['Models', 'Accuracy_score'])\\\n",
    "                            .sort_values('Accuracy_score', ascending=False)\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f6c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6024d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8292a6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "344d2f7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01853150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f184a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1d44937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.6018, Std. Deviation - 0.1138\n",
      "MNB: Mean Accuracy - 0.6022, Std. Deviation - 0.0641\n",
      "XGB: Mean Accuracy - 0.5847, Std. Deviation - 0.0137\n",
      "LR: Mean Accuracy - 0.6368, Std. Deviation - 0.0975\n",
      "LSVC: Mean Accuracy - 0.6252, Std. Deviation - 0.0837\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.79      0.36        14\n",
      "           1       0.71      0.54      0.62       140\n",
      "           2       0.81      0.81      0.81       175\n",
      "\n",
      "    accuracy                           0.70       329\n",
      "   macro avg       0.59      0.71      0.60       329\n",
      "weighted avg       0.74      0.70      0.71       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.79      0.36        14\n",
      "           1       0.77      0.36      0.49       140\n",
      "           2       0.73      0.90      0.81       175\n",
      "\n",
      "    accuracy                           0.67       329\n",
      "   macro avg       0.58      0.68      0.55       329\n",
      "weighted avg       0.72      0.67      0.65       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.64      0.27        14\n",
      "           1       0.65      0.54      0.59       140\n",
      "           2       0.78      0.72      0.75       175\n",
      "\n",
      "    accuracy                           0.64       329\n",
      "   macro avg       0.53      0.63      0.54       329\n",
      "weighted avg       0.70      0.64      0.66       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.86      0.38        14\n",
      "           1       0.69      0.54      0.60       140\n",
      "           2       0.81      0.79      0.80       175\n",
      "\n",
      "    accuracy                           0.68       329\n",
      "   macro avg       0.58      0.73      0.59       329\n",
      "weighted avg       0.73      0.68      0.70       329\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.79      0.37        14\n",
      "           1       0.68      0.54      0.60       140\n",
      "           2       0.79      0.78      0.79       175\n",
      "\n",
      "    accuracy                           0.68       329\n",
      "   macro avg       0.57      0.70      0.59       329\n",
      "weighted avg       0.72      0.68      0.69       329\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 12, stratify = y)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 1), max_features = 500, tokenizer = word_tokenize)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "nr = NearMiss()\n",
    "X_train_nm, y_train_nm = nr.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "models = [\n",
    "    ('RF', RandomForestClassifier()),\n",
    "    ('MNB', MultinomialNB()),\n",
    "    ('XGB', XGBClassifier()),\n",
    "    ('LR', LogisticRegression(max_iter = 1000)),\n",
    "    ('LSVC', LinearSVC())\n",
    "]\n",
    "\n",
    "\n",
    "class_reports = {}\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 5, random_state = 12, shuffle = True)\n",
    "    cv_results = cross_val_score(model, X_train_nm, y_train_nm, cv = kfold, scoring = 'accuracy')\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    \n",
    "    model.fit(X_train_nm, y_train_nm)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    class_reports[name] = classification_report(y_test, y_pred)\n",
    "\n",
    "for name, report in class_reports.items():\n",
    "    print(f\"\\nClassification Report for {name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "65f4cbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.6923, Std. Deviation - 0.0503\n",
      "MNB: Mean Accuracy - 0.6049, Std. Deviation - 0.0873\n",
      "XGB: Mean Accuracy - 0.7031, Std. Deviation - 0.0780\n",
      "LR: Mean Accuracy - 0.6715, Std. Deviation - 0.0499\n",
      "LSVC: Mean Accuracy - 0.6350, Std. Deviation - 0.0616\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.71      0.56         7\n",
      "           1       0.66      0.77      0.71        70\n",
      "           2       0.85      0.69      0.76        88\n",
      "\n",
      "    accuracy                           0.73       165\n",
      "   macro avg       0.65      0.73      0.68       165\n",
      "weighted avg       0.75      0.73      0.73       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.71      0.48         7\n",
      "           1       0.82      0.46      0.59        70\n",
      "           2       0.72      0.92      0.81        88\n",
      "\n",
      "    accuracy                           0.72       165\n",
      "   macro avg       0.63      0.70      0.62       165\n",
      "weighted avg       0.75      0.72      0.70       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.57      0.36         7\n",
      "           1       0.70      0.66      0.68        70\n",
      "           2       0.79      0.75      0.77        88\n",
      "\n",
      "    accuracy                           0.70       165\n",
      "   macro avg       0.58      0.66      0.60       165\n",
      "weighted avg       0.73      0.70      0.71       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.86      0.48         7\n",
      "           1       0.80      0.59      0.68        70\n",
      "           2       0.79      0.86      0.83        88\n",
      "\n",
      "    accuracy                           0.75       165\n",
      "   macro avg       0.64      0.77      0.66       165\n",
      "weighted avg       0.78      0.75      0.75       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.57      0.36         7\n",
      "           1       0.75      0.61      0.68        70\n",
      "           2       0.77      0.82      0.80        88\n",
      "\n",
      "    accuracy                           0.72       165\n",
      "   macro avg       0.60      0.67      0.61       165\n",
      "weighted avg       0.74      0.72      0.73       165\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 12, stratify = y)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 1), max_features = 500, tokenizer = word_tokenize)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "nr = NearMiss()\n",
    "X_train_nm, y_train_nm = nr.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "models = [\n",
    "    ('RF', RandomForestClassifier()),\n",
    "    ('MNB', MultinomialNB()),\n",
    "    ('XGB', XGBClassifier()),\n",
    "    ('LR', LogisticRegression(max_iter = 1000)),\n",
    "    ('LSVC', LinearSVC())\n",
    "]\n",
    "\n",
    "\n",
    "class_reports = {}\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 5, random_state = 12, shuffle = True)\n",
    "    cv_results = cross_val_score(model, X_train_nm, y_train_nm, cv = kfold, scoring = 'accuracy')\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    \n",
    "    model.fit(X_train_nm, y_train_nm)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    class_reports[name] = classification_report(y_test, y_pred)\n",
    "\n",
    "for name, report in class_reports.items():\n",
    "    print(f\"\\nClassification Report for {name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "490a3fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: Mean Accuracy - 0.6397, Std. Deviation - 0.1260\n",
      "MNB: Mean Accuracy - 0.6153, Std. Deviation - 0.1360\n",
      "XGB: Mean Accuracy - 0.6676, Std. Deviation - 0.1513\n",
      "LR: Mean Accuracy - 0.6250, Std. Deviation - 0.1165\n",
      "LSVC: Mean Accuracy - 0.6047, Std. Deviation - 0.1250\n",
      "\n",
      "Classification Report for RF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.57      0.38         7\n",
      "           1       0.67      0.61      0.64        70\n",
      "           2       0.78      0.77      0.78        88\n",
      "\n",
      "    accuracy                           0.70       165\n",
      "   macro avg       0.58      0.65      0.60       165\n",
      "weighted avg       0.71      0.70      0.70       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for MNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.86      0.35         7\n",
      "           1       0.94      0.43      0.59        70\n",
      "           2       0.77      0.93      0.85        88\n",
      "\n",
      "    accuracy                           0.72       165\n",
      "   macro avg       0.64      0.74      0.60       165\n",
      "weighted avg       0.82      0.72      0.72       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for XGB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.71      0.45         7\n",
      "           1       0.63      0.60      0.61        70\n",
      "           2       0.76      0.72      0.74        88\n",
      "\n",
      "    accuracy                           0.67       165\n",
      "   macro avg       0.57      0.68      0.60       165\n",
      "weighted avg       0.68      0.67      0.67       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.71      0.45         7\n",
      "           1       0.74      0.64      0.69        70\n",
      "           2       0.81      0.82      0.81        88\n",
      "\n",
      "    accuracy                           0.74       165\n",
      "   macro avg       0.63      0.73      0.65       165\n",
      "weighted avg       0.76      0.74      0.74       165\n",
      "\n",
      "\n",
      "\n",
      "Classification Report for LSVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.71      0.42         7\n",
      "           1       0.72      0.59      0.65        70\n",
      "           2       0.78      0.81      0.79        88\n",
      "\n",
      "    accuracy                           0.71       165\n",
      "   macro avg       0.60      0.70      0.62       165\n",
      "weighted avg       0.73      0.71      0.71       165\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "X = ml[\"cleaned_text\"]\n",
    "y = ml[\"sentiment_ml\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 12, stratify = y)\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range = (1, 3), max_features = 500, tokenizer = word_tokenize)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "nr = NearMiss()\n",
    "X_train_nm, y_train_nm = nr.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "models = [\n",
    "    ('RF', RandomForestClassifier()),\n",
    "    ('MNB', MultinomialNB()),\n",
    "    ('XGB', XGBClassifier()),\n",
    "    ('LR', LogisticRegression(max_iter = 500)),\n",
    "    ('LSVC', LinearSVC())\n",
    "]\n",
    "\n",
    "\n",
    "class_reports = {}\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold(n_splits = 10, random_state = 12, shuffle = True)\n",
    "    cv_results = cross_val_score(model, X_train_nm, y_train_nm, cv = kfold, scoring = 'accuracy')\n",
    "    print(f\"{name}: Mean Accuracy - {cv_results.mean():.4f}, Std. Deviation - {cv_results.std():.4f}\")\n",
    "    \n",
    "    model.fit(X_train_nm, y_train_nm)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    class_reports[name] = classification_report(y_test, y_pred)\n",
    "\n",
    "for name, report in class_reports.items():\n",
    "    print(f\"\\nClassification Report for {name}:\\n{report}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a5836f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
